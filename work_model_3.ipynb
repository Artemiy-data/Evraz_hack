{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b93b8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, recall_score, precision_score\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pandas import concat\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aa9f5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем RANDOM_SEED, чтобы эксперименты были воспроизводимы:\n",
    "RANDOM_SEED = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c5b75",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "55ca7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_produv(produv_train):\n",
    "    \n",
    "    produv_start=pd.pivot_table(produv_train,index='NPLV',values='SEC', aggfunc={'min'}).reset_index()\n",
    "    produv_end=pd.pivot_table(produv_train,index='NPLV',values='SEC', aggfunc={'max'}).reset_index()\n",
    "    ras_med=pd.pivot_table(produv_train,index='NPLV',values='RAS', aggfunc={'mean'}).reset_index()\n",
    "    ras_sum=pd.pivot_table(produv_train,index='NPLV',values='RAS', aggfunc={'sum'}).reset_index()\n",
    "    pol_start=pd.pivot_table(produv_train,index='NPLV',values='POL', aggfunc={'max'}).reset_index()\n",
    "    pol_end=pd.pivot_table(produv_train,index='NPLV',values='POL', aggfunc={'min'}).reset_index()\n",
    "    \n",
    "    produv_upd=pd.merge(produv_start,produv_end, how='left',on='NPLV')\n",
    "    produv_upd=pd.merge(produv_upd,ras_sum, how='left',on='NPLV')\n",
    "    produv_upd=pd.merge(produv_upd,pol_start, how='left',on='NPLV')\n",
    "    produv_upd=pd.merge(produv_upd,pol_end, how='left',on='NPLV')\n",
    "    \n",
    "    #df.rename(columns = {list(df)[1]:'new_name'}, inplace=True)\n",
    "    \n",
    "    produv_upd.rename(columns={list(produv_upd)[1]: 'PRODUVKA_START'}, inplace=True)\n",
    "    produv_upd.rename(columns={list(produv_upd)[2]: 'PRODUVKA_END'}, inplace=True)\n",
    "    produv_upd.rename(columns={list(produv_upd)[3]: 'RASHOD_SUM'}, inplace=True)\n",
    "    produv_upd.rename(columns={list(produv_upd)[4]: 'POL_MAX'}, inplace=True)\n",
    "    produv_upd.rename(columns={list(produv_upd)[5]: 'POL_MIN'}, inplace=True)\n",
    "    \n",
    "    produv_upd['PRODUVKA_TIME']=produv_upd['PRODUVKA_END']-produv_upd['PRODUVKA_START']\n",
    "    produv_upd['PRODUVKA_TIME,SEC']=produv_upd['PRODUVKA_TIME'].dt.seconds\n",
    "\n",
    "    \n",
    "    return produv_upd\n",
    "\n",
    "\n",
    "def update_gas(gas_train):\n",
    "    V_finish=gas_train[['NPLV','Time','V']].sort_values(by=['NPLV','Time'], ascending=[True,False]).drop_duplicates('NPLV')\n",
    "    V_finish=V_finish.drop('Time', axis=1)\n",
    "    V_start=gas_train[['NPLV','Time','V']].sort_values(by=['NPLV','Time'], ascending=[True,True]).drop_duplicates('NPLV')\n",
    "    V_start=V_start.drop('Time', axis=1)\n",
    "    T_finish=gas_train[['NPLV','Time','T']].sort_values(by=['NPLV','Time'], ascending=[True,False]).drop_duplicates('NPLV')\n",
    "    T_finish=T_finish.drop('Time', axis=1)\n",
    "    T_start=gas_train[['NPLV','Time','T']].sort_values(by=['NPLV','Time'], ascending=[True,True]).drop_duplicates('NPLV')\n",
    "    T_start=T_start.drop('Time', axis=1)\n",
    "    O2_sum=pd.pivot_table(gas_train,index='NPLV',values='O2', aggfunc={'sum'}).reset_index()\n",
    "    N2_sum=pd.pivot_table(gas_train,index='NPLV',values='N2', aggfunc={'sum'}).reset_index()\n",
    "    H2_sum=pd.pivot_table(gas_train,index='NPLV',values='H2', aggfunc={'sum'}).reset_index()\n",
    "    CO2_sum=pd.pivot_table(gas_train,index='NPLV',values='CO2', aggfunc={'sum'}).reset_index()\n",
    "    CO_sum=pd.pivot_table(gas_train,index='NPLV',values='CO', aggfunc={'sum'}).reset_index()\n",
    "    AR_sum=pd.pivot_table(gas_train,index='NPLV',values='AR', aggfunc={'sum'}).reset_index()\n",
    "    TF1_start=gas_train[['NPLV','Time','T фурмы 1']].sort_values(by=['NPLV','Time'], ascending=[True,True]).drop_duplicates('NPLV')\n",
    "    TF1_start=TF1_start.drop('Time', axis=1)\n",
    "    TF1_end=gas_train[['NPLV','Time','T фурмы 1']].sort_values(by=['NPLV','Time'], ascending=[True,False]).drop_duplicates('NPLV')\n",
    "    TF1_end=TF1_end.drop('Time', axis=1)\n",
    "    TF2_start=gas_train[['NPLV','Time','T фурмы 2']].sort_values(by=['NPLV','Time'], ascending=[True,True]).drop_duplicates('NPLV')\n",
    "    TF2_start=TF2_start.drop('Time', axis=1)\n",
    "    TF2_end=gas_train[['NPLV','Time','T фурмы 2']].sort_values(by=['NPLV','Time'], ascending=[True,False]).drop_duplicates('NPLV')\n",
    "    TF2_end=TF2_end.drop('Time', axis=1)\n",
    "    O2_pressure_start=gas_train[['NPLV','Time','O2_pressure']].sort_values(by=['NPLV','Time'], ascending=[True,True]).drop_duplicates('NPLV')\n",
    "    O2_pressure_start=O2_pressure_start.drop('Time', axis=1)\n",
    "    O2_pressure_end=gas_train[['NPLV','Time','O2_pressure']].sort_values(by=['NPLV','Time'], ascending=[True,False]).drop_duplicates('NPLV')\n",
    "    O2_pressure_end=O2_pressure_end.drop('Time', axis=1)\n",
    "    O2_pressure_max=pd.pivot_table(gas_train,index='NPLV',values='O2_pressure', aggfunc={'max'}).reset_index()\n",
    "    O2_pressure_min=pd.pivot_table(gas_train,index='NPLV',values='O2_pressure', aggfunc={'min'}).reset_index()\n",
    "    time_start=pd.pivot_table(gas_train,index='NPLV',values='Time', aggfunc={'min'}).reset_index()\n",
    "    time_end=pd.pivot_table(gas_train,index='NPLV',values='Time', aggfunc={'max'}).reset_index()\n",
    "    tmp_1=pd.merge(time_start, time_end, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, V_start, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, V_finish, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, T_start, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, T_finish, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, O2_sum, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, N2_sum, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, H2_sum, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, CO2_sum, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, CO_sum, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, AR_sum, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, TF1_start, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, TF1_end, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, TF2_start, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, TF2_end, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, O2_pressure_start, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, O2_pressure_end, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, O2_pressure_max, how='left', on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, O2_pressure_min, how='left', on='NPLV')\n",
    "    tmp_1.rename(columns={list(tmp_1)[1]:'GAS_START'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[2]: 'GAS_FINISH'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[3]: 'V_START'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[4]: 'V_FINISH'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[5]: 'T_START'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[6]: 'T_FINISH'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[7]: 'O2_SUM'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[8]: 'N2_SUM'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[9]: 'H2_SUM'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[10]: 'CO2_SUM'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[11]: 'CO_SUM'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[12]: 'AR_SUM'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[13]: 'TF1_START'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[14]: 'TF1_FINISH'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[15]: 'TF2_START'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[16]: 'TF2_FINISH'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[17]: 'O2_PRESSURE_START'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[18]: 'O2_PRESSURE_FINISH'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[19]: 'O2_PRESSURE_MAX'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[20]: 'O2_PRESSURE_MIN'}, inplace=True)\n",
    "    tmp_1['GAS_TIME']=tmp_1['GAS_FINISH']-tmp_1['GAS_START']\n",
    "    tmp_1['GAS_TIME,SEC']=tmp_1['GAS_TIME'].dt.seconds\n",
    "    return tmp_1\n",
    "\n",
    "\n",
    "def update_sip(sip_train):\n",
    "    sip_time_start=sip_train[['NPLV','DAT_OTD']].sort_values(by=['NPLV','DAT_OTD'], ascending=[True,True]).drop_duplicates('NPLV')\n",
    "    sip_time_finish=sip_train[['NPLV','DAT_OTD']].sort_values(by=['NPLV','DAT_OTD'], ascending=[True,False]).drop_duplicates('NPLV')\n",
    "    sip_sostav=pd.pivot_table(sip_train,index='NPLV',columns='VDSYP',values='VSSYP', aggfunc={'sum'})\n",
    "    tmp_1=pd.merge(sip_sostav, sip_time_start, how='left',on='NPLV')\n",
    "    tmp_1=pd.merge(tmp_1, sip_time_finish, how='left',on='NPLV')\n",
    "    tmp_1.rename(columns={list(tmp_1)[1]:'TOTAL_104'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[2]:'TOTAL_119'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[3]:'TOTAL_171'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[4]:'TOTAL_346'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[5]:'TOTAL_397'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[6]:'TOTAL_408'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[7]:'TOTAL_442'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[8]:'SIP_START'}, inplace=True)\n",
    "    tmp_1.rename(columns={list(tmp_1)[9]:'SIP_FINISH'}, inplace=True)\n",
    "    tmp_1['SIP_TIME']=tmp_1['SIP_FINISH']-tmp_1['SIP_START']\n",
    "    tmp_1['SIP_TIME,SEC']=tmp_1['SIP_TIME'].dt.seconds\n",
    "    return tmp_1\n",
    "\n",
    "def update_chronom(df):\n",
    "    \n",
    "    O2_sum=pd.pivot_table(df,index='NPLV',values='O2', aggfunc={'sum'}).reset_index()\n",
    "        \n",
    "    O2_sum.rename(columns={list(O2_sum)[1]: 'O2_SUM'}, inplace=True)      \n",
    "   \n",
    "    return O2_sum\n",
    "\n",
    "\n",
    "def update_lom(lom):\n",
    "    \n",
    "    vdl_sum=pd.pivot_table(lom,index='NPLV',values='VDL', aggfunc={'sum'}).reset_index()\n",
    "    lom_sum=pd.pivot_table(lom,index='NPLV',values='VES', aggfunc={'sum'}).reset_index()\n",
    "    \n",
    "    lom_upd=pd.merge(vdl_sum, lom_sum, how='left',on='NPLV')\n",
    "        \n",
    "    #df.rename(columns = {list(df)[1]:'new_name'}, inplace=True)\n",
    "    \n",
    "    lom_upd.rename(columns={list(lom_upd)[1]: 'VDL_SUM'}, inplace=True)\n",
    "    lom_upd.rename(columns={list(lom_upd)[2]: 'LOM_SUM'}, inplace=True)\n",
    "        \n",
    "    return lom_upd\n",
    "\n",
    "\n",
    "def duplicate_data(df):\n",
    "    '''\n",
    "    Функция для поиска дубликатов.\n",
    "    '''\n",
    "    if len(df) > len(df.drop_duplicates()):\n",
    "        print('Имеются дубликаты')\n",
    "        display(df[df.duplicated()])\n",
    "    else:\n",
    "        print('Дубликатов не обнаружено')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3cdf0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= 'C:/Users/Артемий/Python/EVRAZ_AI/data_task1/'\n",
    "\n",
    "names=['chronom','chugun','gas','lom','plavki','produv','sip']\n",
    "\n",
    "chrom_train=pd.read_csv(path+names[0]+'_train.csv')\n",
    "chugun_train=pd.read_csv(path+names[1]+'_train.csv')\n",
    "gas_train=pd.read_csv(path+names[2]+'_train.csv')\n",
    "lom_train=pd.read_csv(path+names[3]+'_train.csv')\n",
    "plavki_train=pd.read_csv(path+names[4]+'_train.csv')\n",
    "produv_train=pd.read_csv(path+names[5]+'_train.csv')\n",
    "sip_train=pd.read_csv(path+names[6]+'_train.csv')\n",
    "\n",
    "chrom_test=pd.read_csv(path+names[0]+'_test.csv')\n",
    "chugun_test=pd.read_csv(path+names[1]+'_test.csv')\n",
    "gas_test=pd.read_csv(path+names[2]+'_test.csv')\n",
    "lom_test=pd.read_csv(path+names[3]+'_test.csv')\n",
    "plavki_test=pd.read_csv(path+names[4]+'_test.csv')\n",
    "produv_test=pd.read_csv(path+names[5]+'_test.csv')\n",
    "sip_test=pd.read_csv(path+names[6]+'_test.csv')\n",
    "\n",
    "target_train=pd.read_csv(path+'target_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4d3defdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_train['Time']=pd.to_datetime(gas_train['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "gas_train_upd=update_gas(gas_train)\n",
    "sip_train['DAT_OTD']=pd.to_datetime(sip_train['DAT_OTD'], format='%Y-%m-%d %H:%M:%S')\n",
    "sip_train_upd=update_sip(sip_train)\n",
    "chronom_train['VR_NACH']=pd.to_datetime(chronom_train['VR_NACH'], format='%Y-%m-%d %H:%M:%S')\n",
    "chronom_train = chronom_train[chronom_train['VR_NACH'].dt.year > 2020]\n",
    "chronom_train_upd = update_chronom(chronom_train)\n",
    "produv_train['SEC']=pd.to_datetime(produv_train['SEC'], format='%Y-%m-%d %H:%M:%S')\n",
    "produv_train_upd=update_produv(produv_train)\n",
    "lom_train_upd = update_lom(lom_train)\n",
    "plavki_train = plavki_train.drop_duplicates(subset = ['NPLV', 'plavka_STFUT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "01f23bdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-53c5be2a3ce5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgas_test_upd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdate_gas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgas_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msip_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DAT_OTD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msip_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DAT_OTD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msip_test_upd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdate_sip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msip_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mchronom_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'VR_NACH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchronom_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'VR_NACH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mchronom_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchronom_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchronom_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'VR_NACH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2020\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-162-5c0c420a1a1f>\u001b[0m in \u001b[0;36mupdate_sip\u001b[1;34m(sip_train)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mtmp_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'SIP_FINISH'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mtmp_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SIP_TIME'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SIP_FINISH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtmp_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SIP_START'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mtmp_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SIP_TIME,SEC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SIP_TIME'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtmp_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5459\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5460\u001b[0m         ):\n\u001b[1;32m-> 5461\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5462\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mPeriodProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "gas_test['Time']=pd.to_datetime(gas_test['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "gas_test_upd=update_gas(gas_test)\n",
    "sip_test['DAT_OTD']=pd.to_datetime(sip_test['DAT_OTD'], format='%Y-%m-%d %H:%M:%S')\n",
    "sip_test_upd=update_sip(sip_test)\n",
    "chronom_test['VR_NACH']=pd.to_datetime(chronom_test['VR_NACH'], format='%Y-%m-%d %H:%M:%S')\n",
    "chronom_test = chronom_test[chronom_test['VR_NACH'].dt.year > 2020]\n",
    "chronom_test_upd = update_chronom(chronom_test)\n",
    "produv_test['SEC']=pd.to_datetime(produv_test['SEC'], format='%Y-%m-%d %H:%M:%S')\n",
    "produv_test_upd=update_produv(produv_test)\n",
    "lom_test_upd = update_lom(lom_test)\n",
    "plavki_test = plavki_test.drop_duplicates(subset = ['NPLV', 'plavka_STFUT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "423c9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(chugun_train, gas_train_upd, on = ['NPLV'])\n",
    "df_train = df_train.merge(chronom_train_upd, how='right', on = 'NPLV')\n",
    "df_train = df_train.merge(produv_train_upd, how='right', on = 'NPLV')\n",
    "df_train = df_train.merge(lom_train_upd, how='right', on = 'NPLV')\n",
    "df_train = df_train.merge(sip_train_upd, how='right', on = 'NPLV')\n",
    "df_train = df_train.merge(plavki_train, how='right', on = 'NPLV')\n",
    "df_train = df_train.drop(df.columns[[33, 41, 54]], axis=1)\n",
    "df_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d883ba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2063 entries, 0 to 2062\n",
      "Data columns (total 62 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   NPLV                2063 non-null   int64         \n",
      " 1   VES                 2063 non-null   float64       \n",
      " 2   T                   2063 non-null   float64       \n",
      " 3   SI                  2063 non-null   float64       \n",
      " 4   MN                  2063 non-null   float64       \n",
      " 5   S                   2063 non-null   float64       \n",
      " 6   P                   2063 non-null   float64       \n",
      " 7   CR                  2063 non-null   float64       \n",
      " 8   NI                  2063 non-null   float64       \n",
      " 9   CU                  2063 non-null   float64       \n",
      " 10  V                   2063 non-null   float64       \n",
      " 11  TI                  2063 non-null   float64       \n",
      " 12  DATA_ZAMERA         2063 non-null   object        \n",
      " 13  GAS_START           2063 non-null   datetime64[ns]\n",
      " 14  GAS_FINISH          2063 non-null   datetime64[ns]\n",
      " 15  V_START             2063 non-null   float64       \n",
      " 16  V_FINISH            2063 non-null   float64       \n",
      " 17  T_START             2063 non-null   float64       \n",
      " 18  T_FINISH            2063 non-null   float64       \n",
      " 19  CO_SUM              2063 non-null   float64       \n",
      " 20  AR_SUM              2063 non-null   float64       \n",
      " 21  CO_SUM              2063 non-null   float64       \n",
      " 22  AR_SUM              2063 non-null   float64       \n",
      " 23  CO_SUM              2063 non-null   float64       \n",
      " 24  AR_SUM              2063 non-null   float64       \n",
      " 25  TF1_START           2063 non-null   float64       \n",
      " 26  TF1_FINISH          2063 non-null   float64       \n",
      " 27  TF2_START           2063 non-null   float64       \n",
      " 28  TF2_FINISH          2063 non-null   float64       \n",
      " 29  O2_PRESSURE_START   2063 non-null   float64       \n",
      " 30  O2_PRESSURE_FINISH  2063 non-null   float64       \n",
      " 31  O2_PRESSURE_MAX     2063 non-null   float64       \n",
      " 32  O2_PRESSURE_MIN     2063 non-null   float64       \n",
      " 33  GAS_TIME,SEC        2063 non-null   int64         \n",
      " 34  O2_SUM              2063 non-null   float64       \n",
      " 35  PRODUVKA_START      2063 non-null   datetime64[ns]\n",
      " 36  PRODUVKA_END        2063 non-null   datetime64[ns]\n",
      " 37  RASHOD_SUM          2063 non-null   float64       \n",
      " 38  POL_MAX             2063 non-null   float64       \n",
      " 39  POL_MIN             2063 non-null   float64       \n",
      " 40  PRODUVKA_TIME,SEC   2063 non-null   int64         \n",
      " 41  VDL_SUM             2063 non-null   int64         \n",
      " 42  LOM_SUM             2063 non-null   int64         \n",
      " 43  TOTAL_104           2063 non-null   float64       \n",
      " 44  TOTAL_119           2063 non-null   float64       \n",
      " 45  TOTAL_171           2063 non-null   float64       \n",
      " 46  TOTAL_346           2063 non-null   float64       \n",
      " 47  TOTAL_397           2063 non-null   float64       \n",
      " 48  TOTAL_408           2063 non-null   float64       \n",
      " 49  TOTAL_442           2063 non-null   float64       \n",
      " 50  SIP_START           2063 non-null   datetime64[ns]\n",
      " 51  SIP_FINISH          2063 non-null   datetime64[ns]\n",
      " 52  SIP_TIME,SEC        2063 non-null   int64         \n",
      " 53  plavka_VR_NACH      2063 non-null   object        \n",
      " 54  plavka_VR_KON       2063 non-null   object        \n",
      " 55  plavka_NMZ          2063 non-null   object        \n",
      " 56  plavka_NAPR_ZAD     2063 non-null   object        \n",
      " 57  plavka_STFUT        2063 non-null   int64         \n",
      " 58  plavka_TIPE_FUR     2063 non-null   object        \n",
      " 59  plavka_ST_FURM      2063 non-null   int64         \n",
      " 60  plavka_TIPE_GOL     2063 non-null   object        \n",
      " 61  plavka_ST_GOL       2063 non-null   int64         \n",
      "dtypes: datetime64[ns](6), float64(40), int64(9), object(7)\n",
      "memory usage: 1015.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(chugun_test, gas_upd, on = ['NPLV'])\n",
    "df_test = df_test.merge(chronom_upd, how='right', on = 'NPLV')\n",
    "df_test = df_test.merge(produv_upd, how='right', on = 'NPLV')\n",
    "df_test = df_test.merge(lom_upd, how='right', on = 'NPLV')\n",
    "df_test = df_test.merge(sip_upd, how='right', on = 'NPLV')\n",
    "df_test = df_test.merge(plavki_train, how='right', on = 'NPLV')\n",
    "df_test.update(df_test.select_dtypes('float').fillna(0, inplace=True))\n",
    "df_test = df_test.drop(df.columns[[33, 41, 54]], axis=1)\n",
    "df_test.fillna(0, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
